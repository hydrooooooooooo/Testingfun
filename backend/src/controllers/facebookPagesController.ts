import { Request, Response, NextFunction } from 'express';
import { nanoid } from 'nanoid';
import axios from 'axios';
import { sessionService, SessionStatus } from '../services/sessionService';
import { facebookPagesService } from '../services/facebookPagesService';
import { creditService } from '../services/creditService';
import { calculateFacebookPagesCost, calculateAiAnalysisCost, calculateBenchmarkCost, COST_MATRIX } from '../services/costEstimationService';
import { ApiError } from '../middlewares/errorHandler';
import { logger } from '../utils/logger';
import { config } from '../config/config';
import { getDefaultAIModel } from '../config/aiModels';
import db from '../database';
import { persistScrapedItems } from '../services/itemPersistenceService';
import { commentScraperService } from '../services/commentScraperService';
import { saveFacebookPagesBackup } from '../services/backupService';
import { openRouterCostService } from '../services/openRouterCostService';

export class FacebookPagesController {

  async startScrape(req: Request, res: Response, next: NextFunction) {
    try {
      const userId = (req as any).user?.id;
      if (!userId) throw new ApiError(401, 'Authentication required');

      const {
        urls,
        extractInfo = true,
        extractPosts = true,
        extractComments = false,
        postsLimit = 50,
        commentsLimit,
        singlePostUrl,
        dateFrom,
        dateTo,
        incrementalMode = false,
        packId = 'pack-standard',
      } = req.body;

      if (!urls || !Array.isArray(urls) || urls.length === 0) {
        throw new ApiError(400, 'Au moins une URL de page Facebook est requise.');
      }
      if (urls.length > 20) {
        throw new ApiError(400, 'Maximum 20 pages par extraction.');
      }
      for (const url of urls) {
        try {
          const parsed = new URL(url);
          if (!['www.facebook.com', 'facebook.com', 'm.facebook.com'].includes(parsed.hostname)) {
            throw new ApiError(400, `URL invalide: ${url}. Seules les URLs Facebook sont acceptees.`);
          }
        } catch (e) {
          if (e instanceof ApiError) throw e;
          throw new ApiError(400, `URL invalide: ${url}`);
        }
      }

      // Check no active extraction for this user
      const activeSession = await db('scraping_sessions')
        .where({ user_id: userId, scrape_type: 'facebook_pages' })
        .whereIn('status', [SessionStatus.PENDING, SessionStatus.RUNNING])
        .first();
      if (activeSession) {
        throw new ApiError(409, 'Une extraction Facebook Pages est deja en cours.');
      }

      // Estimate cost
      const pageCount = urls.length;
      const postCount = extractPosts ? pageCount * postsLimit : 0;
      const estimate = calculateFacebookPagesCost(
        extractInfo ? pageCount : 0,
        postCount,
        extractComments,
        extractComments ? (commentsLimit || 20) * postCount : 0
      );

      // Reserve credits
      let reservation;
      try {
        reservation = await creditService.reserveCredits(
          userId, estimate, 'facebook_pages',
          `fbpages_${Date.now()}`, `Extraction Facebook Pages (${pageCount} page(s))`
        );
      } catch (error: any) {
        const errMsg = error?.message || String(error);
        if (errMsg.toLowerCase().includes('insufficient') || errMsg.toLowerCase().includes('insuffisant')) {
          throw new ApiError(402, 'Cr√©dits insuffisants pour cette extraction.');
        }
        logger.error(`[FB_PAGES] Credit reservation failed: ${errMsg}`);
        throw new ApiError(500, `Erreur lors de la r√©servation des cr√©dits: ${errMsg}`);
      }

      // Create session
      const sessionId = `sess_${nanoid(10)}`;
      const extractionConfig = {
        extractInfo, extractPosts, extractComments,
        postsLimit, commentsLimit, singlePostUrl,
        dateFrom, dateTo, incrementalMode,
      };

      await sessionService.createSession({
        id: sessionId,
        user_id: userId,
        status: SessionStatus.PENDING,
        packId,
        scrape_type: 'facebook_pages',
        page_urls: JSON.stringify(urls),
        extraction_config: JSON.stringify(extractionConfig),
        sub_sessions: JSON.stringify([]),
        data_types: JSON.stringify({ extractInfo, extractPosts, extractComments }),
      });

      // Log search events for reporting
      try {
        for (const pageUrl of urls) {
          const domain = (() => { try { return new URL(pageUrl).hostname; } catch { return null; } })();
          await db('search_events').insert({
            user_id: userId || null,
            session_id: sessionId,
            url: pageUrl,
            domain,
            status: 'PENDING',
          });
        }
      } catch (e) {
        logger.warn('[FBPages] Failed to log search event', e);
      }

      // Launch pipeline in background
      this.launchPipeline(sessionId, userId, urls, extractionConfig, reservation.id)
        .catch(err => logger.error(`[FBPages] Pipeline error for ${sessionId}:`, err));

      res.status(200).json({ sessionId });
    } catch (error) {
      next(error);
    }
  }

  private async launchPipeline(
    sessionId: string,
    userId: number,
    urls: string[],
    extractionConfig: any,
    reservationId: number
  ): Promise<void> {
    const subSessions: any[] = [];

    try {
      await sessionService.updateSession(sessionId, { status: SessionStatus.RUNNING });

      for (const url of urls) {
        const pageName = this.extractPageName(url);
        const sub: any = { pageName, url };

        if (extractionConfig.extractInfo) {
          try {
            const { runId, datasetId } = await facebookPagesService.startInfoScrape(url);
            sub.infoRunId = runId;
            sub.infoDatasetId = datasetId;
            sub.infoStatus = 'RUNNING';
          } catch (error) {
            logger.error(`[FBPages] Failed to start info scrape for ${url}:`, error);
            sub.infoStatus = 'FAILED';
          }
        }

        if (extractionConfig.extractPosts) {
          try {
            const { runId, datasetId } = await facebookPagesService.startPostsScrape(url, {
              postsLimit: extractionConfig.postsLimit,
              dateFrom: extractionConfig.dateFrom,
              dateTo: extractionConfig.dateTo,
            });
            sub.postsRunId = runId;
            sub.postsDatasetId = datasetId;
            sub.postsStatus = 'RUNNING';
          } catch (error) {
            logger.error(`[FBPages] Failed to start posts scrape for ${url}:`, error);
            sub.postsStatus = 'FAILED';
          }
        }

        subSessions.push(sub);
      }

      // Save initial sub_sessions
      await db('scraping_sessions').where({ id: sessionId }).update({
        sub_sessions: JSON.stringify(subSessions),
        updated_at: new Date(),
      });

      // Poll until complete (max 10 minutes)
      await this.pollUntilComplete(sessionId, subSessions, extractionConfig, 600000);

      // Fetch data for completed runs
      for (const sub of subSessions) {
        if (sub.infoStatus === 'SUCCEEDED' && sub.infoDatasetId) {
          sub.infoData = await facebookPagesService.getDatasetItems(sub.infoDatasetId);
        }
        if (sub.postsStatus === 'SUCCEEDED' && sub.postsDatasetId) {
          sub.postsData = await facebookPagesService.getDatasetItems(sub.postsDatasetId);
        }
      }

      // Start batch comments if requested (non-blocking per sub-session)
      if (extractionConfig.extractComments) {
        for (const sub of subSessions) {
          if (sub.postsData?.length) {
            const postUrls = sub.postsData
              .map((p: any) => p.url || p.postUrl)
              .filter(Boolean);
            if (postUrls.length > 0) {
              try {
                const { runId, datasetId } = await commentScraperService.startBatchComments(
                  postUrls, { resultsLimit: extractionConfig.commentsLimit || 20 }
                );
                sub.commentsRunId = runId;
                sub.commentsDatasetId = datasetId;
                sub.commentsStatus = 'RUNNING';
              } catch (error) {
                logger.error(`[FBPages] Failed to start batch comments for ${sub.pageName}:`, error);
                sub.commentsStatus = 'FAILED';
              }
            }
          }
        }

        // Save sub_sessions with comment run IDs
        await db('scraping_sessions').where({ id: sessionId }).update({
          sub_sessions: JSON.stringify(subSessions),
          updated_at: new Date(),
        });

        // Poll comment runs until complete (max 15 minutes)
        await this.pollCommentsUntilComplete(sessionId, subSessions, 900000);

        // Fetch grouped results and save to DB
        for (const sub of subSessions) {
          if (sub.commentsStatus === 'SUCCEEDED' && sub.commentsDatasetId && sub.commentsRunId) {
            try {
              const results = await commentScraperService.getGroupedCommentResults(
                sub.commentsDatasetId, sub.commentsRunId
              );
              for (const r of results) {
                if (r.comments.length > 0) {
                  await commentScraperService.saveComments(userId, sessionId, r.postUrl, r.comments, r.runId);
                }
              }
              sub.commentsData = results;
            } catch (error) {
              logger.error(`[FBPages] Failed to fetch comment results for ${sub.pageName}:`, error);
            }
          }
        }
      }

      // Persist fetched items to scraped_items table
      for (const sub of subSessions) {
        if (sub.infoData?.length) {
          const infoItems = sub.infoData.map((item: any) => ({
            title: item.name || item.title || sub.pageName || 'Facebook Page',
            price: '',
            desc: item.about || item.description || '',
            image: item.profilePic || item.profilePhoto || '',
            images: [item.profilePic, item.coverPhoto].filter(Boolean),
            location: item.address || item.location || '',
            url: sub.url || '',
            postedAt: '',
          }));
          try {
            await persistScrapedItems(sessionId, userId, infoItems, 'facebook_page_info');
          } catch (err) {
            logger.warn(`[PERSISTENCE] FB info persist failed for ${sessionId}:`, err);
          }
        }
        if (sub.postsData?.length) {
          const postItems = sub.postsData.map((post: any) => ({
            title: (post.text || post.message || '').substring(0, 200) || `Post from ${sub.pageName}`,
            price: '',
            desc: post.text || post.message || '',
            image: post.photoUrl || post.imageUrl || '',
            images: (post.photos || post.images || []).slice(0, 3),
            location: '',
            url: post.url || post.postUrl || '',
            postedAt: post.time || post.date || post.createdTime || '',
          }));
          try {
            await persistScrapedItems(sessionId, userId, postItems, 'facebook_page_post');
          } catch (err) {
            logger.warn(`[PERSISTENCE] FB posts persist failed for ${sessionId}:`, err);
          }
        }
      }

      // Save backup and finalize
      saveFacebookPagesBackup(sessionId, subSessions);

      const totalItems = subSessions.reduce((sum: number, s: any) =>
        sum + (s.postsData?.length || 0) + (s.infoData?.length || 0), 0);

      // Calculate actual cost based on real data fetched (not the estimate)
      const actualPageCount = subSessions.filter((s: any) => s.infoStatus === 'SUCCEEDED').length;
      const actualPostCount = subSessions.reduce((sum: number, s: any) => sum + (s.postsData?.length || 0), 0);
      const actualCommentCount = subSessions.reduce((sum: number, s: any) =>
        sum + (s.commentsData?.reduce((c: number, r: any) => c + (r.totalComments || 0), 0) || 0), 0);
      const actualCost = calculateFacebookPagesCost(
        extractionConfig.extractInfo ? actualPageCount : 0,
        actualPostCount,
        extractionConfig.extractComments || false,
        actualCommentCount
      );

      await db('scraping_sessions').where({ id: sessionId }).update({
        status: SessionStatus.FINISHED,
        sub_sessions: JSON.stringify(subSessions),
        totalItems,
        hasData: totalItems > 0,
        isPaid: true,
        updated_at: new Date(),
      });

      await creditService.confirmReservation(reservationId, actualCost);
      logger.info(`[FBPages] Session ${sessionId} completed. ${totalItems} items. Actual cost: ${actualCost}`);

    } catch (error) {
      logger.error(`[FBPages] Pipeline failed for ${sessionId}:`, error);
      await sessionService.updateSession(sessionId, { status: SessionStatus.FAILED });
      try { await creditService.cancelReservation(reservationId); } catch {}
    }
  }

  private async pollUntilComplete(sessionId: string, subSessions: any[], extractionConfig: any, timeoutMs: number): Promise<void> {
    const startTime = Date.now();
    const POLL_INTERVAL = 5000;

    while (Date.now() - startTime < timeoutMs) {
      let allDone = true;

      for (const sub of subSessions) {
        if (extractionConfig.extractInfo && sub.infoRunId && sub.infoStatus === 'RUNNING') {
          sub.infoStatus = await facebookPagesService.getRunStatus(sub.infoRunId);
          if (sub.infoStatus === 'RUNNING') allDone = false;
        }
        if (extractionConfig.extractPosts && sub.postsRunId && sub.postsStatus === 'RUNNING') {
          sub.postsStatus = await facebookPagesService.getRunStatus(sub.postsRunId);
          if (sub.postsStatus === 'RUNNING') allDone = false;
        }
      }

      await db('scraping_sessions').where({ id: sessionId }).update({
        sub_sessions: JSON.stringify(subSessions),
        updated_at: new Date(),
      });

      if (allDone) return;
      await new Promise(resolve => setTimeout(resolve, POLL_INTERVAL));
    }

    for (const sub of subSessions) {
      if (sub.infoStatus === 'RUNNING') sub.infoStatus = 'TIMED-OUT';
      if (sub.postsStatus === 'RUNNING') sub.postsStatus = 'TIMED-OUT';
    }
  }

  private async pollCommentsUntilComplete(sessionId: string, subSessions: any[], timeoutMs: number): Promise<void> {
    const startTime = Date.now();
    const POLL_INTERVAL = 5000;
    const TERMINAL = ['SUCCEEDED', 'FAILED', 'TIMED-OUT', 'ABORTED', 'ERROR'];

    while (Date.now() - startTime < timeoutMs) {
      let allDone = true;

      for (const sub of subSessions) {
        if (sub.commentsRunId && sub.commentsStatus === 'RUNNING') {
          const runStatus = await commentScraperService.getRunStatus(sub.commentsRunId);
          sub.commentsStatus = runStatus.status;
          if (runStatus.datasetId) sub.commentsDatasetId = runStatus.datasetId;
          if (!TERMINAL.includes(runStatus.status)) allDone = false;
        }
      }

      await db('scraping_sessions').where({ id: sessionId }).update({
        sub_sessions: JSON.stringify(subSessions),
        updated_at: new Date(),
      });

      if (allDone) return;
      await new Promise(resolve => setTimeout(resolve, POLL_INTERVAL));
    }

    for (const sub of subSessions) {
      if (sub.commentsStatus === 'RUNNING') sub.commentsStatus = 'TIMED-OUT';
    }
  }

  async getStatus(req: Request, res: Response, next: NextFunction) {
    try {
      const { sessionId } = req.params;
      const userId = (req as any).user?.id;
      if (!userId) throw new ApiError(401, 'Authentication required');

      const session = await db('scraping_sessions').where({ id: sessionId }).first();
      if (!session) throw new ApiError(404, 'Session not found');
      if (session.user_id !== userId) throw new ApiError(403, 'Not authorized');

      const subSessions = typeof session.sub_sessions === 'string'
        ? JSON.parse(session.sub_sessions || '[]')
        : (session.sub_sessions || []);

      const extractionConfig = typeof session.extraction_config === 'string'
        ? JSON.parse(session.extraction_config || '{}')
        : (session.extraction_config || {});

      const { status: computedStatus, progress } = facebookPagesService.computeOverallStatus(subSessions, extractionConfig);

      const overallStatus = session.status === SessionStatus.FINISHED ? 'SUCCEEDED'
        : session.status === SessionStatus.FAILED ? 'FAILED'
        : computedStatus;

      res.json({
        sessionId,
        overallStatus,
        progress: overallStatus === 'SUCCEEDED' ? 100 : progress,
        subSessions: subSessions.map((s: any) => ({
          pageName: s.pageName,
          url: s.url,
          infoRunId: s.infoRunId,
          infoStatus: s.infoStatus,
          infoDatasetId: s.infoDatasetId,
          postsRunId: s.postsRunId,
          postsStatus: s.postsStatus,
          postsDatasetId: s.postsDatasetId,
          commentsRunId: s.commentsRunId,
          commentsStatus: s.commentsStatus,
        })),
      });
    } catch (error) {
      next(error);
    }
  }

  async getPageInfo(req: Request, res: Response, next: NextFunction) {
    try {
      const { sessionId } = req.params;
      const userId = (req as any).user?.id;
      if (!userId) throw new ApiError(401, 'Authentication required');

      const session = await db('scraping_sessions').where({ id: sessionId }).first();
      if (!session) throw new ApiError(404, 'Session not found');
      if (session.user_id !== userId) throw new ApiError(403, 'Not authorized');

      const { pageName } = req.query;

      // Try backup first, fallback to DB sub_sessions
      let subSessions: any[] = [];
      const backup = facebookPagesService.readBackup(sessionId);
      if (backup?.subSessions) {
        subSessions = backup.subSessions;
      } else {
        const raw = session.sub_sessions;
        subSessions = typeof raw === 'string' ? JSON.parse(raw || '[]') : (raw || []);
        if (!subSessions.length) throw new ApiError(404, 'Session data not found');
      }

      const infoData: any[] = [];
      for (const sub of subSessions) {
        if (!pageName || sub.pageName === pageName) {
          if (sub.infoData?.length) infoData.push(...sub.infoData);
        }
      }

      if (infoData.length === 0) throw new ApiError(404, 'No page info found');
      res.json(infoData.length === 1 ? infoData[0] : infoData);
    } catch (error) {
      next(error);
    }
  }

  async getPagePosts(req: Request, res: Response, next: NextFunction) {
    try {
      const { sessionId } = req.params;
      const userId = (req as any).user?.id;
      if (!userId) throw new ApiError(401, 'Authentication required');

      const session = await db('scraping_sessions').where({ id: sessionId }).first();
      if (!session) throw new ApiError(404, 'Session not found');
      if (session.user_id !== userId) throw new ApiError(403, 'Not authorized');

      const { pageName } = req.query;

      // Try backup first, fallback to DB sub_sessions
      let subSessions: any[] = [];
      const backup = facebookPagesService.readBackup(sessionId);
      if (backup?.subSessions) {
        subSessions = backup.subSessions;
      } else {
        const raw = session.sub_sessions;
        subSessions = typeof raw === 'string' ? JSON.parse(raw || '[]') : (raw || []);
        if (!subSessions.length) throw new ApiError(404, 'Session data not found');
      }

      const postsData: any[] = [];
      for (const sub of subSessions) {
        if (!pageName || sub.pageName === pageName) {
          if (sub.postsData) postsData.push(...sub.postsData);
        }
      }

      res.json(postsData);
    } catch (error) {
      next(error);
    }
  }

  /**
   * GET /sessions/facebook-pages/:sessionId/summary
   * Aggregate stats across all sub-sessions for a FB Pages session
   */
  async getSummary(req: Request, res: Response, next: NextFunction) {
    try {
      const { sessionId } = req.params;
      const userId = (req as any).user?.id;
      if (!userId) throw new ApiError(401, 'Authentication required');

      const session = await db('scraping_sessions').where({ id: sessionId }).first();
      if (!session) throw new ApiError(404, 'Session not found');
      if (session.user_id !== userId) throw new ApiError(403, 'Not authorized');

      // Try backup first, fallback to DB sub_sessions
      let subSessions: any[] = [];
      const backup = facebookPagesService.readBackup(sessionId);
      if (backup?.subSessions) {
        subSessions = backup.subSessions;
      } else {
        const raw = session.sub_sessions;
        subSessions = typeof raw === 'string' ? JSON.parse(raw || '[]') : (raw || []);
      }

      const pagesDetails = subSessions.map((sub: any) => {
        const info = sub.infoData?.[0] || {};
        return {
          pageName: sub.pageName || 'unknown',
          url: sub.url || '',
          likes: parseInt(info.likes) || 0,
          followers: parseInt(info.followers) || 0,
          posts: sub.postsData?.length || 0,
          followings: parseInt(info.followings) || parseInt(info.following) || 0,
        };
      });

      res.json({
        pages: subSessions.length,
        totalLikes: pagesDetails.reduce((s: number, p: any) => s + p.likes, 0),
        totalFollowers: pagesDetails.reduce((s: number, p: any) => s + p.followers, 0),
        totalPosts: pagesDetails.reduce((s: number, p: any) => s + p.posts, 0),
        pagesDetails,
      });
    } catch (error) {
      next(error);
    }
  }

  /**
   * GET /sessions/facebook-pages/:sessionId/ai-analysis/by-page
   * Return per-page AI analysis results stored in the session
   */
  async getAiAnalysisByPage(req: Request, res: Response, next: NextFunction) {
    try {
      const { sessionId } = req.params;
      const userId = (req as any).user?.id;
      if (!userId) throw new ApiError(401, 'Authentication required');

      const session = await db('scraping_sessions').where({ id: sessionId }).first();
      if (!session) throw new ApiError(404, 'Session not found');
      if (session.user_id !== userId) throw new ApiError(403, 'Not authorized');

      const raw = session.ai_analysis_facebook_pages_by_page;
      const analyses = typeof raw === 'string' ? JSON.parse(raw || '{}') : (raw || {});

      res.json(analyses);
    } catch (error) {
      next(error);
    }
  }

  /**
   * Launch AI analysis for a specific page within a FB Pages session
   * POST /sessions/facebook-pages/:sessionId/ai-analysis/page
   */
  async launchAiAnalysisForPage(req: Request, res: Response, next: NextFunction) {
    try {
      const { sessionId } = req.params;
      const { pageName } = req.body;
      const userId = (req as any).user?.id;
      if (!userId) throw new ApiError(401, 'Authentication required');
      if (!pageName) throw new ApiError(400, 'pageName requis');

      const session = await db('scraping_sessions').where({ id: sessionId }).first();
      if (!session) throw new ApiError(404, 'Session not found');
      if (session.user_id !== userId) throw new ApiError(403, 'Not authorized');
      if (session.scrape_type !== 'facebook_pages') throw new ApiError(400, 'Not a Facebook Pages session');

      // Check if already analyzed
      const existingAnalyses = typeof session.ai_analysis_facebook_pages_by_page === 'string'
        ? JSON.parse(session.ai_analysis_facebook_pages_by_page || '{}')
        : (session.ai_analysis_facebook_pages_by_page || {});
      if (existingAnalyses[pageName]) {
        return res.json({ success: true, analysis: existingAnalyses[pageName], alreadyExists: true });
      }

      // Read backup data (with DB fallback)
      let subSession: any;
      const backup = facebookPagesService.readBackup(sessionId);
      if (backup) {
        subSession = backup.subSessions?.find((s: any) => s.pageName === pageName);
      }
      if (!subSession) {
        // Fallback: use sub_sessions stored in DB
        const dbSubSessions = typeof session.sub_sessions === 'string'
          ? JSON.parse(session.sub_sessions || '[]')
          : (session.sub_sessions || []);
        subSession = dbSubSessions.find((s: any) => s.pageName === pageName);
        if (subSession) {
          logger.info(`[AI] Using DB fallback for sub_sessions (backup file missing) session=${sessionId} page=${pageName}`);
        }
      }
      if (!subSession) throw new ApiError(404, `Page "${pageName}" not found in session`);

      const postsData = subSession.postsData || [];
      const infoData = subSession.infoData?.[0] || {};

      // Fetch user's preferred AI model
      const userPrefs = await db('users').where({ id: userId }).select('preferred_ai_model').first();
      const modelId = userPrefs?.preferred_ai_model || getDefaultAIModel().id;

      // Calculate cost & reserve credits (with model multiplier)
      const cost = calculateAiAnalysisCost(1, postsData.length, modelId);
      let reservation;
      try {
        reservation = await creditService.reserveCredits(
          userId, cost, 'ai_analysis',
          `ai_${sessionId}_${pageName.replace(/\s+/g, '_')}`,
          `Analyse IA: ${pageName} (${postsData.length} posts)`
        );
      } catch (error: any) {
        const errMsg = error?.message || String(error);
        if (errMsg.toLowerCase().includes('insufficient') || errMsg.toLowerCase().includes('insuffisant')) {
          const userBalance = await creditService.getUserCreditBalance(userId);
          logger.warn(`[AI] Insufficient credits for user ${userId}: required=${cost}, available=${userBalance.total}, model=${modelId}`);
          throw new ApiError(402, `Cr√©dits insuffisants. Requis: ${cost.toFixed(1)}, disponible: ${userBalance.total.toFixed(1)}`);
        }
        logger.error(`[AI] Credit reservation failed for user ${userId}: ${errMsg}`, { sessionId, pageName, cost, modelId });
        throw new ApiError(500, `Erreur lors de la r√©servation des cr√©dits: ${errMsg}`);
      }

      try {
        const result = await this.callOpenRouterForAudit(pageName, infoData, postsData, modelId);
        const analysis = result.analysis;

        // Log AI usage (fire-and-forget)
        if (result.generationId) {
          openRouterCostService.logAIUsage({
            userId,
            sessionId,
            generationId: result.generationId,
            model: modelId,
            agentType: 'audit',
            creditsCharged: cost,
            pageName,
          }).catch(err => logger.warn('[AI] Failed to log AI usage:', err.message));
        }

        existingAnalyses[pageName] = {
          raw: JSON.stringify(analysis),
          model: modelId,
          costCredits: cost,
          created_at: new Date().toISOString(),
        };

        await db('scraping_sessions').where({ id: sessionId }).update({
          ai_analysis_facebook_pages_by_page: JSON.stringify(existingAnalyses),
          updated_at: new Date(),
        });

        await creditService.confirmReservation(reservation.id, cost);
        logger.info(`[AI] Analysis completed for ${pageName} in session ${sessionId}. Cost: ${cost}`);
        res.json({ success: true, analysis: existingAnalyses[pageName] });
      } catch (error) {
        try { await creditService.cancelReservation(reservation.id); } catch {}
        throw error;
      }
    } catch (error) {
      next(error);
    }
  }

  /**
   * Launch benchmark for a specific page within a FB Pages session
   * POST /sessions/facebook-pages/:sessionId/ai-benchmark/page
   */
  async launchBenchmarkForPage(req: Request, res: Response, next: NextFunction) {
    try {
      const { sessionId } = req.params;
      const { pageName } = req.body;
      const userId = (req as any).user?.id;
      if (!userId) throw new ApiError(401, 'Authentication required');
      if (!pageName) throw new ApiError(400, 'pageName requis');

      const session = await db('scraping_sessions').where({ id: sessionId }).first();
      if (!session) throw new ApiError(404, 'Session not found');
      if (session.user_id !== userId) throw new ApiError(403, 'Not authorized');
      if (session.scrape_type !== 'facebook_pages') throw new ApiError(400, 'Not a Facebook Pages session');

      // Check if already benchmarked
      const existingBenchmarks = typeof session.ai_benchmark_facebook_pages_by_page === 'string'
        ? JSON.parse(session.ai_benchmark_facebook_pages_by_page || '{}')
        : (session.ai_benchmark_facebook_pages_by_page || {});
      if (existingBenchmarks[pageName]) {
        return res.json({ success: true, benchmark: existingBenchmarks[pageName], alreadyExists: true });
      }

      // Read backup data (with DB fallback)
      let subSession: any;
      const backup = facebookPagesService.readBackup(sessionId);
      if (backup) {
        subSession = backup.subSessions?.find((s: any) => s.pageName === pageName);
      }
      if (!subSession) {
        // Fallback: use sub_sessions stored in DB
        const dbSubSessions = typeof session.sub_sessions === 'string'
          ? JSON.parse(session.sub_sessions || '[]')
          : (session.sub_sessions || []);
        subSession = dbSubSessions.find((s: any) => s.pageName === pageName);
        if (subSession) {
          logger.info(`[BENCHMARK] Using DB fallback for sub_sessions (backup file missing) session=${sessionId} page=${pageName}`);
        }
      }
      if (!subSession) throw new ApiError(404, `Page "${pageName}" not found in session`);

      const postsData = subSession.postsData || [];
      const infoData = subSession.infoData?.[0] || {};

      // Fetch user's preferred AI model
      const userPrefs = await db('users').where({ id: userId }).select('preferred_ai_model').first();
      const modelId = userPrefs?.preferred_ai_model || getDefaultAIModel().id;

      // Calculate cost & reserve credits (benchmark: perPage + perPost*n + aiAnalysis + reportGeneration)
      const cost = calculateBenchmarkCost(1, postsData.length, true, modelId);
      let reservation;
      try {
        reservation = await creditService.reserveCredits(
          userId, cost, 'facebook_pages_benchmark',
          `bench_${sessionId}_${pageName.replace(/\s+/g, '_')}`,
          `Benchmark: ${pageName} (${postsData.length} posts)`
        );
      } catch (error: any) {
        const errMsg = error?.message || String(error);
        if (errMsg.toLowerCase().includes('insufficient') || errMsg.toLowerCase().includes('insuffisant')) {
          throw new ApiError(402, 'Cr√©dits insuffisants pour ce benchmark.');
        }
        logger.error(`[BENCHMARK] Credit reservation failed: ${errMsg}`, { sessionId, pageName, cost, modelId });
        throw new ApiError(500, `Erreur lors de la r√©servation des cr√©dits: ${errMsg}`);
      }

      try {
        const result = await this.callOpenRouterForBenchmark(pageName, infoData, postsData, modelId);
        const benchmark = result.analysis;

        // Log AI usage (fire-and-forget)
        if (result.generationId) {
          openRouterCostService.logAIUsage({
            userId,
            sessionId,
            generationId: result.generationId,
            model: modelId,
            agentType: 'benchmark',
            creditsCharged: cost,
            pageName,
          }).catch(err => logger.warn('[AI] Failed to log AI usage:', err.message));
        }

        existingBenchmarks[pageName] = {
          raw: JSON.stringify(benchmark),
          model: modelId,
          costCredits: cost,
          created_at: new Date().toISOString(),
        };

        await db('scraping_sessions').where({ id: sessionId }).update({
          ai_benchmark_facebook_pages_by_page: JSON.stringify(existingBenchmarks),
          updated_at: new Date(),
        });

        await creditService.confirmReservation(reservation.id, cost);
        logger.info(`[AI] Benchmark completed for ${pageName} in session ${sessionId}. Cost: ${cost}`);
        res.json({ success: true, benchmark: existingBenchmarks[pageName] });
      } catch (error) {
        try { await creditService.cancelReservation(reservation.id); } catch {}
        throw error;
      }
    } catch (error) {
      next(error);
    }
  }

  /**
   * Call OpenRouter for page audit analysis
   */
  private async callOpenRouterForAudit(pageName: string, infoData: any, postsData: any[], modelId: string): Promise<{ analysis: any; generationId: string; usage: any }> {
    const openRouterKey = config.ai.openRouterApiKey;
    if (!openRouterKey) {
      return { analysis: this.generateBasicAudit(pageName, infoData, postsData), generationId: '', usage: {} };
    }

    try {
      const postsSample = postsData.slice(0, 15).map((p: any, i: number) => ({
        idx: i + 1,
        text: (p.text || p.message || '').substring(0, 200),
        likes: parseInt(p.likes) || 0,
        comments: parseInt(p.comments) || 0,
        shares: parseInt(p.shares) || 0,
        type: p.videoUrl ? 'video' : p.photoUrl ? 'photo' : 'text',
        date: p.time || p.date || '',
      }));

      const totalPosts = postsData.length;
      const avgLikes = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.likes) || 0), 0) / totalPosts) : 0;
      const avgComments = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.comments) || 0), 0) / totalPosts) : 0;
      const avgShares = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.shares) || 0), 0) / totalPosts) : 0;

      const prompt = `Tu es un expert en marketing digital et social media. Analyse cette page Facebook et produis un audit complet en JSON.

Page: ${pageName}
Cat√©gorie: ${infoData.category || infoData.categories?.[0] || 'Non sp√©cifi√©'}
Followers: ${infoData.followers || infoData.likes || 'N/A'}
Description: ${(infoData.intro || infoData.about || infoData.info?.join(' ') || '').substring(0, 300)}

Statistiques: ${totalPosts} posts analys√©s, moyenne ${avgLikes} likes, ${avgComments} commentaires, ${avgShares} partages.

√âchantillon de posts:
${postsSample.map(p => `#${p.idx} [${p.type}] "${p.text}..." ‚Äî ${p.likes}‚ù§ ${p.comments}üí¨ ${p.shares}üîÅ (${p.date})`).join('\n')}

G√©n√®re un JSON avec EXACTEMENT cette structure:
{
  "audit_summary": {
    "engagement_score": { "score": <1-10>, "label": "<Faible|Moyen|Bon|Excellent>" },
    "global_health": "<diagnostic global en 2-3 phrases>",
    "key_insight": "<l'insight le plus important>"
  },
  "quantitative_analysis": {
    "averages": { "likes": ${avgLikes}, "comments": ${avgComments}, "shares": ${avgShares}, "engagement_total": ${avgLikes + avgComments + avgShares} },
    "top_posts": [<top 3 posts: { "texte": "...", "metrics": { "likes": N, "comments": N, "shares": N }, "explanation": "pourquoi √ßa marche" }>],
    "flop_posts": [<3 posts les moins performants: { "texte": "...", "metrics": {...}, "explanation": "...", "improvement_recommendation": "..." }>]
  },
  "what_is_working_well": [{ "strength": "...", "data_proof": "...", "recommendation": "comment amplifier" }],
  "pain_points_and_fixes": [{ "problem": "...", "data_evidence": "...", "quick_fix": { "action": "...", "example": "..." } }],
  "creative_ideas_to_test": [{ "idea_name": "...", "description": "...", "implementation": { "example_post": "..." }, "expected_benefit": "..." }],
  "final_verdict": {
    "one_thing_to_stop": "...",
    "one_thing_to_start": "...",
    "one_thing_to_amplify": "..."
  }
}`;

      const response = await axios.post(
        `${config.ai.openRouterBaseUrl}/chat/completions`,
        {
          model: modelId,
          messages: [{ role: 'user', content: prompt }],
          temperature: 0.3,
        },
        {
          headers: {
            'Authorization': `Bearer ${openRouterKey}`,
            'Content-Type': 'application/json',
          },
          timeout: 90000,
        }
      );

      const generationId = response.data.id || '';
      const usage = response.data.usage || {};
      const content = response.data.choices?.[0]?.message?.content || '';
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        return { analysis: JSON.parse(jsonMatch[0]), generationId, usage };
      }
      logger.warn(`[AI] Could not parse audit JSON response for ${pageName}`);
      return { analysis: this.generateBasicAudit(pageName, infoData, postsData), generationId, usage };
    } catch (error: any) {
      logger.error(`[AI] OpenRouter audit call failed for ${pageName}:`, error.message);
    }

    return { analysis: this.generateBasicAudit(pageName, infoData, postsData), generationId: '', usage: {} };
  }

  /**
   * Call OpenRouter for competitive benchmark analysis
   */
  private async callOpenRouterForBenchmark(pageName: string, infoData: any, postsData: any[], modelId: string): Promise<{ analysis: any; generationId: string; usage: any }> {
    const openRouterKey = config.ai.openRouterApiKey;
    if (!openRouterKey) {
      return { analysis: this.generateBasicBenchmark(pageName, infoData, postsData), generationId: '', usage: {} };
    }

    try {
      const totalPosts = postsData.length;
      const avgLikes = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.likes) || 0), 0) / totalPosts) : 0;
      const avgComments = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.comments) || 0), 0) / totalPosts) : 0;
      const avgShares = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.shares) || 0), 0) / totalPosts) : 0;
      const followers = parseInt(infoData.followers) || parseInt(infoData.likes) || 0;
      const engagementRate = followers > 0 ? Math.round(((avgLikes + avgComments + avgShares) / followers) * 10000) / 100 : 0;

      const prompt = `Tu es un expert en benchmark concurrentiel sur les r√©seaux sociaux. Analyse cette page Facebook par rapport aux standards de son secteur.

Page: ${pageName}
Cat√©gorie: ${infoData.category || infoData.categories?.[0] || 'Non sp√©cifi√©'}
Followers: ${followers}
Description: ${(infoData.intro || infoData.about || '').substring(0, 300)}

M√©triques: ${totalPosts} posts, moy. ${avgLikes} likes, ${avgComments} comments, ${avgShares} shares, engagement rate: ${engagementRate}%

G√©n√®re un JSON avec EXACTEMENT cette structure:
{
  "meta": { "sector_detected": "<secteur d√©tect√©>", "analysis_date": "${new Date().toISOString()}" },
  "benchmark_positioning": {
    "overall_score": <1-10>,
    "position": "<Leader|Challenger|Suiveur|Outsider>"
  },
  "metrics_comparison": {
    "likes": { "page_average": ${avgLikes}, "sector_benchmark": <estimation benchmark secteur>, "gap_percentage": "<+X% ou -X%>" },
    "comments": { "page_average": ${avgComments}, "sector_benchmark": <estimation>, "gap_percentage": "<+X% ou -X%>" },
    "shares": { "page_average": ${avgShares}, "sector_benchmark": <estimation>, "gap_percentage": "<+X% ou -X%>" },
    "engagement_rate": { "page_average": "${engagementRate}%", "sector_benchmark": "<estimation>%" }
  },
  "competitive_gaps": [{ "gap_name": "...", "severity": "HIGH|MEDIUM|LOW", "current_state": "...", "sector_best_practice": "...", "impact_if_fixed": "..." }],
  "differentiation_opportunities": [{ "opportunity": "...", "why_unique": "...", "implementation": "...", "competitive_advantage": "..." }],
  "strategies_to_adopt": [{ "strategy_name": "...", "source": "...", "adaptation": "...", "example_post": "...", "expected_impact": "..." }],
  "action_plan": {
    "immediate_actions": [{ "action": "...", "effort": "Faible|Moyen|√âlev√©", "expected_result": "..." }]
  }
}`;

      const response = await axios.post(
        `${config.ai.openRouterBaseUrl}/chat/completions`,
        {
          model: modelId,
          messages: [{ role: 'user', content: prompt }],
          temperature: 0.3,
        },
        {
          headers: {
            'Authorization': `Bearer ${openRouterKey}`,
            'Content-Type': 'application/json',
          },
          timeout: 90000,
        }
      );

      const generationId = response.data.id || '';
      const usage = response.data.usage || {};
      const content = response.data.choices?.[0]?.message?.content || '';
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        // Fill missing fields from fallback (AI often truncates the last fields)
        const fallback = this.generateBasicBenchmark(pageName, infoData, postsData);
        if (!parsed.strategies_to_adopt?.length) parsed.strategies_to_adopt = fallback.strategies_to_adopt;
        if (!parsed.action_plan?.immediate_actions?.length) parsed.action_plan = fallback.action_plan;
        return { analysis: parsed, generationId, usage };
      }
      logger.warn(`[AI] Could not parse benchmark JSON response for ${pageName}`);
      return { analysis: this.generateBasicBenchmark(pageName, infoData, postsData), generationId, usage };
    } catch (error: any) {
      logger.error(`[AI] OpenRouter benchmark call failed for ${pageName}:`, error.message);
    }

    return { analysis: this.generateBasicBenchmark(pageName, infoData, postsData), generationId: '', usage: {} };
  }

  /**
   * Generate a basic audit without AI (fallback)
   */
  private generateBasicAudit(pageName: string, infoData: any, postsData: any[]): any {
    const totalPosts = postsData.length;
    const avgLikes = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.likes) || 0), 0) / totalPosts) : 0;
    const avgComments = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.comments) || 0), 0) / totalPosts) : 0;
    const avgShares = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.shares) || 0), 0) / totalPosts) : 0;

    const sorted = [...postsData].sort((a: any, b: any) => (parseInt(b.likes) || 0) - (parseInt(a.likes) || 0));
    const top3 = sorted.slice(0, 3).map((p: any) => ({
      texte: (p.text || p.message || 'Post sans texte').substring(0, 150),
      metrics: { likes: parseInt(p.likes) || 0, comments: parseInt(p.comments) || 0, shares: parseInt(p.shares) || 0 },
      explanation: 'Post avec bon engagement',
    }));
    const flop3 = sorted.slice(-3).reverse().map((p: any) => ({
      texte: (p.text || p.message || 'Post sans texte').substring(0, 150),
      metrics: { likes: parseInt(p.likes) || 0, comments: parseInt(p.comments) || 0, shares: parseInt(p.shares) || 0 },
      explanation: 'Engagement faible',
      improvement_recommendation: 'Ajouter un visuel ou un call-to-action',
    }));

    const score = avgLikes > 100 ? 7 : avgLikes > 50 ? 5 : avgLikes > 10 ? 3 : 1;

    return {
      audit_summary: {
        engagement_score: { score, label: score >= 7 ? 'Bon' : score >= 4 ? 'Moyen' : 'Faible' },
        global_health: `La page ${pageName} a ${totalPosts} publications avec une moyenne de ${avgLikes} likes par post. Le niveau d'engagement est ${score >= 7 ? 'bon' : score >= 4 ? 'moyen' : 'faible'}.`,
        key_insight: `Avec ${avgLikes} likes moyens et ${avgComments} commentaires par post, il y a une opportunit√© d'am√©liorer l'interaction avec la communaut√©.`,
      },
      quantitative_analysis: {
        averages: { likes: avgLikes, comments: avgComments, shares: avgShares, engagement_total: avgLikes + avgComments + avgShares },
        top_posts: top3,
        flop_posts: flop3,
      },
      what_is_working_well: [
        { strength: 'Pr√©sence active sur Facebook', data_proof: `${totalPosts} publications analys√©es`, recommendation: 'Maintenir la fr√©quence de publication' },
      ],
      pain_points_and_fixes: [
        { problem: 'Engagement √† optimiser', data_evidence: `Moyenne de ${avgComments} commentaires par post`, quick_fix: { action: 'Poser des questions dans les publications', example: 'Et vous, qu\'en pensez-vous ? Dites-nous en commentaire !' } },
      ],
      creative_ideas_to_test: [
        { idea_name: 'S√©rie vid√©o hebdomadaire', description: 'Cr√©er un rendez-vous r√©current en vid√©o', implementation: { example_post: `[Vid√©o] D√©couvrez les coulisses de ${pageName} chaque vendredi !` }, expected_benefit: 'Augmenter les partages et la fid√©lisation' },
      ],
      final_verdict: {
        one_thing_to_stop: 'Publier du contenu sans visuel',
        one_thing_to_start: 'Int√©grer des appels √† l\'action dans chaque post',
        one_thing_to_amplify: 'Les formats qui g√©n√®rent le plus de partages',
      },
    };
  }

  /**
   * Generate a basic benchmark without AI (fallback)
   */
  private generateBasicBenchmark(pageName: string, infoData: any, postsData: any[]): any {
    const totalPosts = postsData.length;
    const avgLikes = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.likes) || 0), 0) / totalPosts) : 0;
    const avgComments = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.comments) || 0), 0) / totalPosts) : 0;
    const avgShares = totalPosts > 0 ? Math.round(postsData.reduce((s: number, p: any) => s + (parseInt(p.shares) || 0), 0) / totalPosts) : 0;
    const followers = parseInt(infoData.followers) || parseInt(infoData.likes) || 0;
    const engagementRate = followers > 0 ? Math.round(((avgLikes + avgComments + avgShares) / followers) * 10000) / 100 : 0;

    const score = avgLikes > 100 ? 7 : avgLikes > 50 ? 5 : avgLikes > 10 ? 3 : 2;

    return {
      meta: { sector_detected: infoData.category || 'G√©n√©ral', analysis_date: new Date().toISOString() },
      benchmark_positioning: {
        overall_score: score,
        position: score >= 7 ? 'Leader' : score >= 5 ? 'Challenger' : score >= 3 ? 'Suiveur' : 'Outsider',
      },
      metrics_comparison: {
        likes: { page_average: avgLikes, sector_benchmark: Math.round(avgLikes * 1.3), gap_percentage: '-23%' },
        comments: { page_average: avgComments, sector_benchmark: Math.round(avgComments * 1.2), gap_percentage: '-17%' },
        shares: { page_average: avgShares, sector_benchmark: Math.round(avgShares * 1.4), gap_percentage: '-29%' },
        engagement_rate: { page_average: `${engagementRate}%`, sector_benchmark: `${(engagementRate * 1.3).toFixed(2)}%` },
      },
      competitive_gaps: [
        { gap_name: 'Fr√©quence de publication', severity: 'MEDIUM', current_state: `${totalPosts} posts analys√©s`, sector_best_practice: 'Publication quotidienne recommand√©e', impact_if_fixed: 'Augmentation de 20-30% de la visibilit√©' },
      ],
      differentiation_opportunities: [
        { opportunity: 'Contenu vid√©o natif', why_unique: 'Format privil√©gi√© par l\'algorithme Facebook', implementation: 'Cr√©er 2-3 vid√©os courtes par semaine', competitive_advantage: 'Port√©e organique 3x sup√©rieure aux images' },
      ],
      strategies_to_adopt: [
        { strategy_name: 'Engagement communautaire', source: 'Best practices du secteur', adaptation: `Adapter √† l'audience de ${pageName}`, example_post: 'Question du jour : quel est votre [sujet] pr√©f√©r√© ? R√©pondez en commentaire !', expected_impact: '+40% de commentaires' },
      ],
      action_plan: {
        immediate_actions: [
          { action: 'Augmenter la fr√©quence de publication', effort: 'Moyen', expected_result: '+25% de port√©e en 4 semaines' },
          { action: 'Ajouter des CTA dans chaque post', effort: 'Faible', expected_result: '+15% de clics' },
        ],
      },
    };
  }

  private extractPageName(url: string): string {
    try {
      const urlObj = new URL(url);
      const pathParts = urlObj.pathname.split('/').filter(Boolean);
      return pathParts[0] || 'unknown';
    } catch {
      return 'unknown';
    }
  }
}

export const facebookPagesController = new FacebookPagesController();
